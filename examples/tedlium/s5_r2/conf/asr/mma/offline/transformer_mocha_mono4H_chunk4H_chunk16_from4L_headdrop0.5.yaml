### topology
n_stacks: 1
n_skips: 1
max_n_frames: 1600
conv_in_channel: 1
conv_channels: "32_32_32"
conv_kernel_sizes: "(3,3)_(3,3)_(3,3)"
conv_strides: "(1,1)_(1,1)_(1,1)"
conv_poolings: "(2,2)_(2,2)_(2,2)"
conv_batch_norm: false
conv_layer_norm: false
enc_type: conv_transformer
dec_type: transformer
enc_n_layers: 12
dec_n_layers: 6
transformer_attn_type: mocha
mocha_n_heads_mono: 4
mocha_n_heads_chunk: 4  ###
mocha_chunk_size: 16  ###
mocha_init_r: -2.0
mocha_eps: 1e-6
mocha_std: 1.0
mocha_quantity_loss_weight: 0.0
mocha_first_layer: 4  ###
transformer_enc_pe_type: none  ###
transformer_dec_pe_type: 1dconv3L  ### this is effective
transformer_d_model: 256
transformer_d_ff: 2048
transformer_ffn_activation: relu
transformer_n_heads: 4
transformer_param_init: xavier_uniform
tie_embedding: false
ctc_fc_list: "512"
### optimization
batch_size: 32
optimizer: noam
n_epochs: 25
convert_to_sgd_epoch: 100
print_step: 600  ### 200->600
metric: accuracy
lr_factor: 5.0
early_stop_patient_n_epochs: 5
shuffle_bucket: true  ### this is important
sort_stop_epoch: 100
eval_start_epoch: 1
warmup_n_steps: 25000
accum_grad_n_steps: 8
### regularization
clip_grad_norm: 5.0
dropout_in: 0.0
dropout_enc: 0.1
dropout_dec: 0.1
dropout_emb: 0.1
dropout_att: 0.0
dropout_head: 0.5  ###
weight_decay: 1e-6
lsm_prob: 0.1
### MTL
ctc_weight: 0.3
ctc_lsm_prob: 0.1
mtl_per_batch: false
task_specific_layer: false
